"use strict";(self.webpackChunkvuepress_theme_hope_template=self.webpackChunkvuepress_theme_hope_template||[]).push([[357],{6262:(a,s)=>{s.A=(a,s)=>{const n=a.__vccOpts||a;for(const[a,e]of s)n[a]=e;return n}},1802:(a,s,n)=>{n.r(s),n.d(s,{comp:()=>o,data:()=>r});var e=n(641);const t=n.p+"assets/img/image_1.9edbecf9.png",i=[(0,e.Fv)('<h1 id="实验指令相关" tabindex="-1"><a class="header-anchor" href="#实验指令相关"><span>实验指令相关</span></a></h1><h3 id="训练指令" tabindex="-1"><a class="header-anchor" href="#训练指令"><span>训练指令</span></a></h3><p>train.sh 文件下修改运行train.py的参数，如--nothing,--dataset,--fusion_mode</p><p>tee：保存命令行的输出结果，结果保存在./trainlog_mosei/mylog.log路径下，-a代表以追加的形式</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train_origin.sh <span class="token parameter variable">--nothing</span> <span class="token parameter variable">--dataset</span> mosei <span class="token parameter variable">--fusion_mode</span> inter_intra <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train_tcp.sh <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog_tcp.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>消融实验</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train_origin.sh <span class="token parameter variable">--nothing</span> <span class="token parameter variable">--dataset</span> mosei <span class="token parameter variable">--fusion_mode</span> inter_intra <span class="token parameter variable">--without_modality</span> t <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog_wt.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="可视化指令" tabindex="-1"><a class="header-anchor" href="#可视化指令"><span>可视化指令</span></a></h3><p><strong>visualize.sh</strong>文件下，可视化注意力机制的结果，通过运行<strong>visualize.py</strong>文件，可指定参数 <strong>--visualize 样本名</strong>，得到对应样本的attention_weight，为一字典类型，包含global（fusion_mode为global时）; inter，intra（fusion_mode为inter_intra时）模型的注意力结果，shape为(layers, bsz, num_heads, q_len, kv_len)</p><p>总共涉及到2个文件：visualize.py，model_attenvisualize.py</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> visualize.sh <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./visualizelog_mosei/mylog.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="对齐操作" tabindex="-1"><a class="header-anchor" href="#对齐操作"><span>对齐操作</span></a></h3><ol><li><p>首先，使用<strong>d\\数据集\\mosei\\raw\\audio\\full</strong>目录下的whisper_rec.py获取所需要得到time_stamps的音频文件（修改音频路径，存储路径）</p></li><li><p>接着运行服务器上目录为**/autodl-tmp/alpaca-lora/ljh/code/**下的sim2.py文件，获取得到对齐结果，存储在pkl文件中（修改存储路径）</p></li><li><p>接着本地对视频（<strong>d\\数据集\\mosei\\load.py</strong>）、音频进行clip（<strong>d\\数据集\\mosei\\clip-audio.py</strong>）（修改存储路径）</p></li></ol><h3 id="自训练" tabindex="-1"><a class="header-anchor" href="#自训练"><span>自训练</span></a></h3><p>基于预训练模型，跑一遍推理；输出csv文件，每类选取top_k个样本（confidence），扩充训练集，重新训练模型，冻结regression头，重新训练p次</p><p>首先进行预训练，通过修改模型参数保存路径，保存到指定路径下</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train.sh <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>从指定路径下加载模型参数，运行以下指令，会读取/root/autodl-tmp/alpaca-lora/ljh/DPC_KNN/data/ami/ami_audiofilter.csv文件，推理ami数据集，得到伪标签，保存结果在/root/autodl-tmp/alpaca-lora/ljh/code/distill_gate/SFIN_origin/ami_result/ami_pred.csv文件中，运行目录下的analysis.py文件，会得到滤除后的top-10样本的预测，即每个类别选取10个高置信度的样本，最终得到filter_ami_pred.csv文件（以追加的形式），基于该文件重新训练模型，指令的运行顺序如下：</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train.sh <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog.log <span class="token comment"># 模型参数保存路径指定，每次重新训练路径最好保持不一致</span>\npython inf_ami_args.py <span class="token comment"># 输入ami_audiofilter.csv，模型参数；输出：ami_pred.csv</span>\npython analysis.py <span class="token comment"># 输入：ami_pred.csv 追加的形式输出：filter_ami_pred.csv，同时更新ami_auidofilter.csv,即剩余的未推理的ami样本</span>\n<span class="token function">bash</span> train.sh <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog.log <span class="token comment"># 输入：filter_ami_pred.csv，模型参数保存路径指定，指定为retrain模式</span>\npython inf_ami_args.py <span class="token comment"># 输入ami_audiofilter.csv，模型参数；输出：ami_pred.csv</span>\npython analysis.py <span class="token comment"># 输入：ami_pred.csv 追加的形式输出：filter_ami_pred.csv，同时更新ami_auidofilter.csv,即剩余的未推理的ami样本</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>现在retrain的想法是，val head损失由mosei数据集提供，emo head的损失由mosei+ami数据集提供。</p><p>已封装成相关指令，循环自训练的指令</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">bash</span> train.sh <span class="token parameter variable">--nothing</span> <span class="token parameter variable">--dataset</span> mosei <span class="token parameter variable">--fusion_mode</span> inter_intra <span class="token parameter variable">--retrain</span> <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token parameter variable">-a</span> ./trainlog_mosei/mylog.log\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>每次重新自训练前，需要更新初始模型，路径在<u><strong>model_single/mosei/inter_intramodelf1.pt</strong></u>中，需更换为初始模型，路径在<u><strong>model_single_originvideo/mosei/inter_intramodelf.pt</strong></u>，更换**<u>ami_audiofilter.csv</u><strong>为初始版本，删除</strong><u>ami_result/ami_pred.csv</u><strong>，</strong><u>ami_result/filter_ami_pred.csv</u>**</p><h3 id="画图" tabindex="-1"><a class="header-anchor" href="#画图"><span>画图</span></a></h3><p>让坐标轴的label始终对准每一小格的中间，思路：首先得到每一个grid的size，然后获取坐标的起止，让每个刻度都加grid_size/2，终止刻度也要加0.5，传入即可</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 获取横坐标轴的范围</span>\nx_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5 12.5 13.5</span>\n<span class="token comment"># 计算一个小格的长度</span>\ngrid_size <span class="token operator">=</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span> <span class="token comment">#word为每一小格放置的label</span>\nticks <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min <span class="token operator">+</span> grid_size<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">,</span> x_max <span class="token operator">+</span> grid_size<span class="token operator">/</span><span class="token number">2</span> <span class="token punctuation">,</span> grid_size<span class="token punctuation">)</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="'+t+'" alt="image-20240325160500471"></p>',28)],p={},o=(0,n(6262).A)(p,[["render",function(a,s){return(0,e.uX)(),(0,e.CE)("div",null,i)}]]),r=JSON.parse('{"path":"/posts/exp/training_order.html","title":"实验指令相关","lang":"zh-CN","frontmatter":{"icon":"pen-to-square","date":"2024-05-06T00:00:00.000Z","category":["实验","训练指令"],"tag":["实验"],"description":"实验指令相关 训练指令 train.sh 文件下修改运行train.py的参数，如--nothing,--dataset,--fusion_mode tee：保存命令行的输出结果，结果保存在./trainlog_mosei/mylog.log路径下，-a代表以追加的形式 消融实验 可视化指令 visualize.sh文件下，可视化注意力机制的结果，通过...","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/myblog/posts/exp/training_order.html"}],["meta",{"property":"og:site_name","content":"Ljh\'s Blog"}],["meta",{"property":"og:title","content":"实验指令相关"}],["meta",{"property":"og:description","content":"实验指令相关 训练指令 train.sh 文件下修改运行train.py的参数，如--nothing,--dataset,--fusion_mode tee：保存命令行的输出结果，结果保存在./trainlog_mosei/mylog.log路径下，-a代表以追加的形式 消融实验 可视化指令 visualize.sh文件下，可视化注意力机制的结果，通过..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Jinhao Lin"}],["meta",{"property":"article:tag","content":"实验"}],["meta",{"property":"article:published_time","content":"2024-05-06T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"实验指令相关\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-06T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Jinhao Lin\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":3,"title":"训练指令","slug":"训练指令","link":"#训练指令","children":[]},{"level":3,"title":"可视化指令","slug":"可视化指令","link":"#可视化指令","children":[]},{"level":3,"title":"对齐操作","slug":"对齐操作","link":"#对齐操作","children":[]},{"level":3,"title":"自训练","slug":"自训练","link":"#自训练","children":[]},{"level":3,"title":"画图","slug":"画图","link":"#画图","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.04,"words":913},"filePathRelative":"posts/exp/training_order.md","localizedDate":"2024年5月6日","excerpt":"\\n<h3>训练指令</h3>\\n<p>train.sh 文件下修改运行train.py的参数，如--nothing,--dataset,--fusion_mode</p>\\n<p>tee：保存命令行的输出结果，结果保存在./trainlog_mosei/mylog.log路径下，-a代表以追加的形式</p>\\n<div class=\\"language-bash\\" data-ext=\\"sh\\" data-title=\\"sh\\"><pre class=\\"language-bash\\"><code><span class=\\"token function\\">bash</span> train_origin.sh <span class=\\"token parameter variable\\">--nothing</span> <span class=\\"token parameter variable\\">--dataset</span> mosei <span class=\\"token parameter variable\\">--fusion_mode</span> inter_intra <span class=\\"token operator\\"><span class=\\"token file-descriptor important\\">2</span>&gt;</span><span class=\\"token file-descriptor important\\">&amp;1</span> <span class=\\"token operator\\">|</span> <span class=\\"token function\\">tee</span> <span class=\\"token parameter variable\\">-a</span> ./trainlog_mosei/mylog.log\\n</code></pre></div>","autoDesc":true}')}}]);