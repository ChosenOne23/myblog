{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{311:function(t,v,_){t.exports=_.p+\"assets/img/image-20240229120637462.32d8b67e.png\"},312:function(t,v,_){t.exports=_.p+\"assets/img/image-20240229120702532.d48fc392.png\"},313:function(t,v,_){t.exports=_.p+\"assets/img/image-20240229161624322.5b47acdf.png\"},314:function(t,v,_){t.exports=_.p+\"assets/img/image-20240229165723875.018df6a2.png\"},315:function(t,v,_){t.exports=_.p+\"assets/img/image-20240229160945980.2fb1d9a3.png\"},316:function(t,v,_){t.exports=_.p+\"assets/img/image-20240304161829784.6f8d1924.png\"},317:function(t,v,_){t.exports=_.p+\"assets/img/image-20240304212702894.6a8b04b3.png\"},318:function(t,v,_){t.exports=_.p+\"assets/img/image-20240304214814123.220cc41a.png\"},319:function(t,v,_){t.exports=_.p+\"assets/img/image-20240304221018613.230b17fd.png\"},320:function(t,v,_){t.exports=_.p+\"assets/img/image-20240307135602509.124a343d.png\"},342:function(t,v,_){\"use strict\";_.r(v);var e=_(14),a=Object(e.a)({},(function(){var t=this,v=t._self._c;return v(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[v(\"h3\",{attrs:{id:\"\"}},[v(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#\"}},[t._v(\"#\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"ol\",[v(\"li\",[v(\"p\",[t._v(\"跨层参数共享\")]),t._v(\" \"),v(\"img\",{staticStyle:{zoom:\"50%\"},attrs:{src:_(311),alt:\"image-20240229120637462\"}})])]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"优点：需保存的参数量降低，减少存储成本。减少训练时间\")]),t._v(\" \"),v(\"p\",[t._v(\"缺点：推理时间仍然一样\")])]),t._v(\" \"),v(\"img\",{staticStyle:{zoom:\"67%\"},attrs:{src:_(312),alt:\"image-20240229120702532\"}}),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"共享不同参数层的结果\")])]),t._v(\" \"),v(\"img\",{staticStyle:{zoom:\"67%\"},attrs:{src:\"https://pic1.zhimg.com/v2-8ea109ed6f3a3781951402a6cf7cc586_r.jpg?source=1def8aca\",alt:\"img\"}}),t._v(\" \"),v(\"ol\",{attrs:{start:\"2\"}},[v(\"li\",[v(\"p\",[t._v(\"词向量因式分解\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"引入一全连接层，将词向量维度降维，达到降低transformer中隐层维度的目的\")])])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"渐进式知识蒸馏\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"MobileBERT:学生模型开始学习教师模型的第一层，接下来学习教师模型的第二层，而此时学生模型的第一层权重是不参与更新的。依此类推。\")])])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"注意力机制的改进（longformer）\")]),t._v(\" \"),v(\"blockquote\",[v(\"ul\",[v(\"li\",[v(\"p\",[t._v(\"滑动窗口注意力\")]),t._v(\" \"),v(\"p\",[t._v(\"当前token仅与左右k/2个token窗口内的token计算注意力\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"扩张窗口注意力\")]),t._v(\" \"),v(\"p\",[t._v(\"在窗口内不是与所有token计算注意力而是进行采样，与窗口内被采样到的token计算注意力（采样间隔）\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"全局+滑动窗口\")]),t._v(\" \"),v(\"p\",[t._v(\"将QKV映射两种不同的子空间，这两种不同的QK,分别计算全局（与具体任务有关，如具有全局视角的CLS，则该token可以关注其他所有token的信息）和滑动窗口注意力\")])])])])])]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(313),alt:\"\"}})]),t._v(\" \"),v(\"h3\",{attrs:{id:\"idea\"}},[v(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#idea\"}},[t._v(\"#\")]),t._v(\" idea\")]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"ol\",[v(\"li\",[t._v(\"缺失模态下的情感分析\")])]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"首先，预训练，基于MLM策略（动态掩码（Robeta）/静态掩码）\")]),t._v(\" \"),v(\"p\",[t._v(\"接着，基于预训练好的的重建模型，提取特征，模态融合模块，进行情感预测\")])]),t._v(\" \"),v(\"ol\",{attrs:{start:\"2\"}},[v(\"li\",[t._v(\"相关的掩码策略（NLP，BART）\")])]),t._v(\" \"),v(\"ul\",[v(\"li\",[v(\"p\",[t._v(\"单词掩码，在输入文本中随机采样一部分单词，并且替换为掩码标记如[MASK]\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"单词删除，随机采样一部分单词并且删除。在预测缺失单词的同时还需要确定缺失单词的位置\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"句子排列变换。将多个句子的顺序随机打乱\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"文档旋转变换\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"文本填充\")])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"实体级别掩码，在普通的单词掩码中，模型只需要根据J.与Rowling就可以做出正确的预测，而无法学习到更高层次的语义\")]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(314),alt:\"image-20240229165723875\"}})]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(315),alt:\"image-20240229160945980\"}})])])]),t._v(\" \"),v(\"ol\",{attrs:{start:\"3\"}},[v(\"li\",[t._v(\"门控策略\")])]),t._v(\" \"),v(\"ul\",[v(\"li\",[t._v(\"输入信号经非线性变换映射至[0,1]，得到门控向量，与原始输入进行元素点乘\")])]),t._v(\" \"),v(\"ol\",{attrs:{start:\"4\"}},[v(\"li\",[t._v(\"bert相关\")])]),t._v(\" \"),v(\"ul\",[v(\"li\",[v(\"p\",[t._v(\"词向量编码，块编码，位置编码\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"词向量编码由独热向量经由词向量矩阵（可学习参数矩阵）映射得到\")]),t._v(\" \"),v(\"p\",[t._v(\"块编码指的是当前token属于哪一句子，属于句子0则编码为0，属于句子1则编码为1，以此类推。运用块向量矩阵进行映射得到最终的块编码\")]),t._v(\" \"),v(\"p\",[t._v(\"位置编码则是将按单词顺序转换为独热编码，再经由位置向量矩阵转换为位置编码\")])]),t._v(\" \"),v(\"img\",{staticStyle:{zoom:\"67%\"},attrs:{src:_(316),alt:\"image-20240304161829784\"}})]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"MLM实现\")]),t._v(\" \"),v(\"p\",[t._v(\"在得到掩码位置的隐向量后，经由词向量矩阵，映射到词表空间，之后经softmax操作得到词表中的词对应该掩码位置的概率，取max即为预测的单词，模型对第i个掩码位置的预测概率的计算如下：\\n$$\\nP(i)=Softmax(h_{i}W_{}^{T}+b)\\n$$\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"整词掩码：掩码的最小粒度为单词级而非wordpiece级，提升了mlm任务的难度，模型在预测掩码词时，需要更多依靠上下文信息，有助于提升模型对输入文本语义信息的挖掘\")]),t._v(\" \"),v(\"p\",[t._v(\"需要注意的是，整词掩码中，子词的掩码方式可以是替换为[MASK]，随机词或者保留原词，三选一；各个子词均会受到掩码；掩码的方式受到概率控制\")])])]),t._v(\" \"),v(\"li\",[v(\"p\",[t._v(\"下游任务\")]),t._v(\" \"),v(\"p\",[t._v(\"抽取式阅读理解：将问题和篇章输入至模型，问题在前，篇章在后，篇章超过最大允许输入长度时，分段输入。在获取得到每个位置起点、终点位置的概率，分别取top-k个，假设起点终点位置相互独立，则联合概率为二者相乘，得到一个[start,end,prob]的三元组，数量为k*k个，添加限制条件start<end，筛选得到最终的结果。\")])])]),t._v(\" \"),v(\"h3\",{attrs:{id:\"code\"}},[v(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#code\"}},[t._v(\"#\")]),t._v(\" code\")]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"ol\",[v(\"li\",[v(\"p\",[t._v(\"链表\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"环的入口节点，如果一链表中包含环，如何确定环的起点\")]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(317),alt:\"image-20240304212702894\"}})]),t._v(\" \"),v(\"p\",[t._v(\"解法：双指针，通过快慢指针找到处于环中的节点，快指针每次走两步，慢指针每次走一步，由于链表存在环，因此最终肯定会碰上（快的会追上慢的，rectify:快指针多走n步，随后两个指针每次都是走一步），重复的位置就是处于环中的节点。\"),v(\"strong\",[t._v(\"接着如果快慢指针每次走的步长相差为环的长度的整数倍，则最终必会在入口处碰上\")]),t._v(\"(rectify:初始时，快指针多走环的长度的步长，接着每次都走一步)，问题转化为寻找环的长度的问题，环的长度可以通过单指针实现，在步骤一中得到的起始节点出发，走一遍，并进行计数，最终就能得到环的长度。接着进行步骤二就能找到入口节点。\")])])])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"链表中倒数第K个节点\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：双指针，快指针初始多走k（\"),v(\"strong\",[t._v(\"k-1\")]),t._v(\"）步，接着每次都走一步，快指针到终点时，慢指针刚好指向倒数第k个节点。\")]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(318),alt:\"image-20240304214814123\"}})])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"调整数组顺序使奇数位于偶数前面\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：双指针，奇偶（分别向中心移动），奇奇（\"),v(\"strong\",[t._v(\"while到奇数\")]),t._v(\"左指针+1），偶偶（右指针-1），偶奇（交换）\")]),t._v(\" \"),v(\"p\",[t._v(\"2，1，4，5，3\")]),t._v(\" \"),v(\"p\",[t._v(\"3，1，4，5，2\")]),t._v(\" \"),v(\"p\",[t._v(\"3，1，5，4，2\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"ul\",[v(\"li\",[t._v(\"删除链表的节点：给定单向链表的头指针和一个节点指针，定义一个函数在O(1)时间内删除该节点\")])]),t._v(\" \"),v(\"p\",[t._v(\"解法：有了要删除的节点指针，可以知道该节点的下一个节点，把下一个节点的值赋值给要删除的节点，将当前节点的next指向下下个节点，\"),v(\"strong\",[t._v(\"除此之外还需要把待删除节点指向的下一个节点删除\")]),t._v(\"。倘若在尾部，只能顺序查找删除\")]),t._v(\" \"),v(\"p\",[v(\"img\",{attrs:{src:_(319),alt:\"image-20240304221018613\"}})]),t._v(\" \"),v(\"p\",[t._v(\"时间复杂度的分析\")]),t._v(\" \"),v(\"p\",[t._v(\"((n-1)*O(1)+O(n))/n=O(1a)\")]),t._v(\" \"),v(\"ul\",[v(\"li\",[t._v(\"删除已排序链表中重复的节点\")])]),t._v(\" \"),v(\"p\",[t._v(\"双指针\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"打印从1到最大的n位数\")]),t._v(\" \"),v(\"p\",[t._v(\"常规做法会出现越界问题，考点是字符串的数字加法及终止条件的判定\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"数值的整数次方\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：先举例子\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"二进制中1的个数\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：输入的二进制数与0001进行与运算，若为1则说明最低位存在1，接着左移一位，得到0010，即与输入的二进制数的次低位进行与运算，判断次低位是否为1，以此类推\")])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"反转链表\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：由于当前节点和下个节点的顺序反转后，链表出现了断裂，即下个节点与下下个节点之间的链接出现断裂，因此需要记录三个节点的信息，\")]),t._v(\" \"),v(\"div\",{staticClass:\"language- extra-class\"},[v(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[v(\"code\",[t._v(\"prev_node = nullptr\\nwhile(p->node!=nullptr)\\n{\\nnext_node = p->node->next\\np->node->next = prev_node\\nprev_node = p->node\\np->node = next_node\\n}\\n\")])])])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"合并两个排序链表\")]),t._v(\" \"),v(\"p\",[t._v(\"解法：比较两个链表头节点的大小，将小的一个作为合并后链表的头节点，接着继续合并链表中的剩余节点\")]),t._v(\" \"),v(\"img\",{staticStyle:{zoom:\"50%\"},attrs:{src:_(320),alt:\"image-20240307135602509\"}}),t._v(\" \"),v(\"div\",{staticClass:\"language- extra-class\"},[v(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[v(\"code\",[t._v(\"mergehead\\nif phead1->value < phead2->value:\\n\\tmergehead=phead1\\n\\tmergehead=\\n\")])])])]),t._v(\" \"),v(\"hr\"),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"树的子结构\")])]),t._v(\" \"),v(\"p\",[t._v(\"**\")]),t._v(\" \"),v(\"blockquote\",[v(\"p\",[t._v(\"二叉树的镜像\")])])])}),[],!1,null,null,null);v.default=a.exports}}]);","extractedComments":[]}