{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{317:function(t,a,e){t.exports=e.p+\"assets/img/image-20240320140335166.9ed76ffc.png\"},318:function(t,a,e){t.exports=e.p+\"assets/img/image-20240320134318989.825d2e4a.png\"},319:function(t,a,e){t.exports=e.p+\"assets/img/image-20240311144051942.5d0505c6.png\"},320:function(t,a,e){t.exports=e.p+\"assets/img/image-20240311150509143.8928e961.png\"},321:function(t,a,e){t.exports=e.p+\"assets/img/image-20240314174857894.574c00c8.png\"},349:function(t,a,e){\"use strict\";e.r(a);var r=e(14),s=Object(r.a)({},(function(){var t=this,a=t._self._c;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"h3\",{attrs:{id:\"a-facial-expression-aware-multimodal-multi-task-learning-framework-for-emotion-recognition-in-multi-party-conversations\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#a-facial-expression-aware-multimodal-multi-task-learning-framework-for-emotion-recognition-in-multi-party-conversations\"}},[t._v(\"#\")]),t._v(\" A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"​\\t一段视频输入talknet得到可能的说话人的帧序列（有可能是错误的，因此需要后续的匹配操作），将这些帧序列进行聚类，由于meld数据集包含6个不同的说话人，因此，预先从数据集中得到每个人20张不同角度的人脸图片，针对聚类完成得到可能说话人的帧序列，经由resnet-50(pretrained on face recongnition dataset)提取对应的特征，计算相似度得到最终的结果\")]),t._v(\" \"),a(\"p\",[a(\"img\",{staticStyle:{zoom:\"50%\"},attrs:{src:e(317),alt:\"image-20240320140335166\"}}),a(\"img\",{staticStyle:{zoom:\"50%\"},attrs:{src:e(318),alt:\"image-20240320134318989\"}})]),t._v(\" \"),a(\"h3\",{attrs:{id:\"emt-dlfr\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#emt-dlfr\"}},[t._v(\"#\")]),t._v(\" EMT_DLFR\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"前向两次，分别得到完整模态，缺失模态的结果\")]),t._v(\" \"),a(\"p\",[t._v(\"在不同epoch下的同一样本，缺失的time step是一样的。而cutoff则是不一样的。能否在训练时人为构造更多的缺失样本，一方面可以避免过拟合，一方面模拟更多真实世界的缺失模态情况\")]),t._v(\" \"),a(\"p\",[t._v(\"跨层参数共享，global2local的attention,将注意力的计算降低至线性复杂度\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"robust-msa\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#robust-msa\"}},[t._v(\"#\")]),t._v(\" Robust-MSA\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"端到端的方式；情感词的识别与replace；asr error；语音的背景噪声（人声分离？）；图像中人脸角度，不同光照，人脸缺失，运动模糊\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"niat\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#niat\"}},[t._v(\"#\")]),t._v(\" NIAT\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"三种模态在对齐的情况下，设置了三种不一样的缺失情况：三种模态缺失的位置均不一致（随机位置缺失）；三种模态缺失的位置一致（连续片段缺失，随机位置缺失）\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"unimf\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#unimf\"}},[t._v(\"#\")]),t._v(\" UniMF\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"提出不同的mask机制，解决未对齐序列缺失模态的问题\")]),t._v(\" \"),a(\"p\",[t._v(\"图中橘色部分有：\\n$$\\nY_{[multi]} = CA_{L->[multi]}([multi],Z_{L})+CA_{A->[multi]}([multi],Z_{A})+SA([multi])\\n$$\\n\"),a(\"img\",{attrs:{src:e(319),alt:\"image-20240311144051942\"}})]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"构造两种不同的mask,一种学习模态内部的交互，一种学习模态间的交互。并采用balence策略\")])]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:e(320),alt:\"image-20240311150509143\"}})]),t._v(\" \"),a(\"h3\",{attrs:{id:\"半监督的paper\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#半监督的paper\"}},[t._v(\"#\")]),t._v(\" 半监督的paper\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"​\\t第一篇，关键是balence所生成的样本类别数目，作者对每一类选取top-k置信度的样本，保证了重新训练时样本数量的平衡\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"p\",[t._v(\"门控机制\")]),t._v(\" \"),a(\"img\",{staticStyle:{zoom:\"50%\"},attrs:{src:e(321),alt:\"image-20240314174857894\"}})])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"my-paper\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#my-paper\"}},[t._v(\"#\")]),t._v(\" my paper\")]),t._v(\" \"),a(\"hr\"),t._v(\" \"),a(\"p\",[t._v(\"单一视角（intra） vs 多视角（inter）\")]),t._v(\" \"),a(\"p\",[t._v(\"有的时候，我们仅仅通过单一一种模态，便能做出很好的感情推断，无需其他模态的帮助：\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"only inf from text:\")]),t._v(\" \"),a(\"ol\",[a(\"li\",[t._v(\"a lot of sad parts\")]),t._v(\" \"),a(\"li\",[t._v(\"there is sad part\")])])]),t._v(\" \"),a(\"p\",[t._v(\"但有时我们需要借助其他模态的帮助(交互信息)从而准确判断主体的情感：\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"inf from text and visual:\")]),t._v(\" \"),a(\"p\",[t._v(\"netural text: AND THERE BUT THEYRE NOT HUGE GLARING FLAWS\")]),t._v(\" \"),a(\"p\",[t._v(\"negative video: frown\")]),t._v(\" \"),a(\"p\",[a(\"video\",{attrs:{src:\"C:\\\\Users\\\\LinJinhao\\\\Desktop\\\\2WGyTLYerpo_49.mp4\"}})])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"meta-noise\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#meta-noise\"}},[t._v(\"#\")]),t._v(\" meta_noise\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"元学习相关资料：https://zhuanlan.zhihu.com/p/72920138，https://zhuanlan.zhihu.com/p/57864886\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"mask-autoencoder\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mask-autoencoder\"}},[t._v(\"#\")]),t._v(\" mask autoencoder\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"https://zhuanlan.zhihu.com/p/439554945\")])]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"p\",[a(\"a\",{attrs:{href:\"https://blog.csdn.net/qq_43631827/article/details/124987612\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"离线数据增强与在线数据增强\"),a(\"OutboundLink\")],1)])]),t._v(\" \"),a(\"li\",[a(\"p\",[a(\"a\",{attrs:{href:\"https://zhuanlan.zhihu.com/p/70257427\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"xlnet\"),a(\"OutboundLink\")],1)])]),t._v(\" \"),a(\"li\",[a(\"p\",[t._v(\"top-k准确率的计算\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"https://zhuanlan.zhihu.com/p/340760336\")])])]),t._v(\" \"),a(\"li\",[a(\"p\",[t._v(\"项目使用的分类代码\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"https://github.com/bubbliiiing/classification-pytorch\")])])])])])}),[],!1,null,null,null);a.default=s.exports}}]);","extractedComments":[]}